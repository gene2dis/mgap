import os
import pandas as pd
import argparse
import json

def get_sample_names(input_folder):
    """
    Function to read the folder generated by MGAP and get the sample ids
    """
    sample_names = []
    for folder in os.listdir(input_folder):
        if folder == "pipeline_info":
            continue
        else:
            sample_names.append(folder)

    return sample_names

def parse_read_processing(input_folder, sample):
    """
    Function to parse the read processing output of MGAP, including
    FASTP, Bracken, and MASH results
    """
    # Process the fastp json

    try:
        fastp_json = json.load(open(input_folder + "/" + sample + "/read_processing/fastp/" + sample + ".fastp.json"))
        before_reads = fastp_json["summary"]["before_filtering"]["total_reads"]
        after_reads = fastp_json["summary"]["after_filtering"]["total_reads"]
        before_bases = fastp_json["summary"]["before_filtering"]["total_bases"]
        after_bases = fastp_json["summary"]["after_filtering"]["total_bases"]

    except FileNotFoundError:
        # If the fastp json file is not found, set the values to 0
        before_reads = 0
        after_reads = 0
        before_bases = 0
        after_bases = 0

    fastp_out = pd.DataFrame(
        {"reads_before": before_reads,
         "reads_after": after_reads,
         "bases_before": before_bases,
         "bases_after": after_bases},
         index = [sample]
    )

    # Process the mash results
    mash_stats = []

    try:
        with open(input_folder + "/" + sample + "/read_processing/mash/" + sample + ".mash_stats") as mash_file:
            for line in mash_file:
                if line.startswith("Estimated genome size"):
                    mash_stats.append(line.strip().split()[-1])
                if line.startswith("Estimated coverage"):
                    mash_stats.append(line.strip().split()[-1])
    except FileNotFoundError:
        # If the mash stats file is not found, set the values to 0
        mash_stats.append(0)
        mash_stats.append(0)

    mash_out = pd.DataFrame(
        {"genome_size": mash_stats[0],
         "coverage": mash_stats[1]},
         index = [sample]
    )

    # Process the bracken results
    try:
        bracken_out_raw = pd.read_csv(input_folder + "/" + sample + "/read_processing/bracken/" + sample + ".tsv", sep="\t")
        bracken_out_raw["sample"] = sample
        bracken_out_raw = bracken_out_raw.set_index("sample")
        bracken_out_filtered = bracken_out_raw[bracken_out_raw["fraction_total_reads"] > 0.01]

    except FileNotFoundError:
        # If the bracken stats file is not found, set the values to 0
        bracken_out_filtered = pd.DataFrame()


    return fastp_out, mash_out, bracken_out_filtered

def parse_assembly_qc(input_folder, sample):
    """
    Function to parse the assembly QC results of MGAP
    """
    qc_results = []
    with open(input_folder + "/" + sample + "/qc/quast/" + sample + ".tsv") as quast_tsv:
        for line in quast_tsv:
            elements = line.strip().split("\t")

            if elements[0] == "# contigs (>= 0 bp)":
                qc_results.append(elements[1])
            if elements[0] == "# contigs (>= 10000 bp)":
                qc_results.append(elements[1])
            if elements[0] == "# contigs (>= 50000 bp)":
                qc_results.append(elements[1])
            if elements[0] == "# contigs":
                qc_results.append(elements[1])
            if elements[0] == "Total length (>= 0 bp)":
                qc_results.append(elements[1])
            if elements[0] == "Total length (>= 10000 bp)":
                qc_results.append(elements[1])
            if elements[0] == "Total length (>= 50000 bp)":
                qc_results.append(elements[1])
            if elements[0] == "Total length":
                qc_results.append(elements[1])
            if elements[0] == "Largest contig":
                qc_results.append(elements[1])
            if elements[0] == "GC (%)":
                qc_results.append(elements[1])
            if elements[0] == "N50":
                qc_results.append(elements[1])

    qc_out = pd.DataFrame(
        {"contigs_0": qc_results[0],
         "contigs_10k": qc_results[1],
         "contigs_50k": qc_results[2],
         "contigs_total": qc_results[3],
         "length_0": qc_results[4],
         "length_10k": qc_results[5],
         "length_50k": qc_results[6],
         "length_total": qc_results[7],
         "largest_contig": qc_results[8],
         "gc": qc_results[9],
         "n50": qc_results[10]},
         index = [sample]
    )

    return(qc_out)

def parse_checkm2(checkm2_file, sample):
    """
    Function to parse the checkm2 results
    """
    cm2_file = pd.read_csv(checkm2_file, sep="\t")
    cm2_file["sample"] = sample
    cm2_file = cm2_file.set_index("sample")
    cm2_file.drop(columns = ["Name"], inplace=True)

    return cm2_file

def parse_mlst(mlst_file, sample):
    """
    Function to parse the MLST results. It has to be able to handle
    a variable number of columns
    """
    with open(mlst_file) as mlst:
        for line in mlst:
            line = line.strip().split("\t")
            species_mlst = line[1]
            st = line[2]
            alleles = line[3:]

            mlst_dict = {
                "species": species_mlst,
                "ST": st
            }

            for allele in alleles:
                name = "gene_" + str(alleles.index(allele) + 1)
                mlst_dict[name] = allele


            mlst_parsed = pd.DataFrame(
                mlst_dict,
                index = [sample]
            )
    return mlst_parsed

def parse_bakta(bakta_result, sample):
    """
    Function to parse the bakta results
    """
    bakta_parsed = pd.read_csv(bakta_result, sep="\t",
                               header=None, skiprows=3,
                               names=["contig", "type", "start", "stop", "strand",
                                      "locus tag", "gene", "product", "dbxrefs"])
    bakta_parsed["sample"] = sample
    bakta_parsed = bakta_parsed.set_index("sample")

    return bakta_parsed

def parse_amrfinder(amrfinder_result, sample):
    """
    Function to parse the amrfinder results
    """
    amrfinder_parsed = pd.read_csv(amrfinder_result, sep="\t")
    amrfinder_parsed["sample"] = sample
    amrfinder_parsed = amrfinder_parsed.set_index("sample")

    return amrfinder_parsed

def parse_genomad(genomad_result, sample):
    """
    Function to parse the genomad results
    """
    genomad_parsed = pd.read_csv(genomad_result, sep="\t")
    genomad_parsed["sample"] = sample
    genomad_parsed = genomad_parsed.set_index("sample")

    return genomad_parsed


def parse_annotation(input_folder, sample):
    """
    Function to parse the annotation results of MGAP
    """

    # Parse checkm2
    checkm2_out = parse_checkm2(input_folder + "/" + sample + "/annotation/checkm2/" + sample + ".quality_report.tsv",
                                sample)

    mlst_out = parse_mlst(input_folder + "/" + sample + "/annotation/mlst/" + sample + ".tsv",
                          sample)

    bakta_out = parse_bakta(input_folder + "/" + sample + "/annotation/bakta/" + sample + ".tsv",
                            sample)

    amrfinder_out = parse_amrfinder(input_folder + "/" + sample + "/annotation/amrfinder/" + sample + ".tsv",
                                    sample)

    genomad_virus_out = parse_genomad(input_folder + "/" + sample + "/annotation/genomad/" + sample + "_virus_summary.tsv",
                                      sample)

    genomad_plasmid_out = parse_genomad(input_folder + "/" + sample + "/annotation/genomad/" + sample + "_plasmid_summary.tsv",
                                      sample)




    return checkm2_out, mlst_out, bakta_out, amrfinder_out, genomad_virus_out, genomad_plasmid_out

def parse_kleborate(input_folder, sample):
    """
    Function to parse the kleborate results
    """
    kleborate_out = pd.read_csv(input_folder + "/" + sample + "/annotation/kleborate/" + sample + ".results.txt",
                                sep="\t")
    kleborate_out.rename(columns={"strain": "sample"}, inplace=True)
    kleborate_out = kleborate_out.set_index("sample")

    return kleborate_out

def parse_sccmec(input_folder, sample):
    """
    Function to parse the sccmec results
    """
    sccmec_out = pd.read_csv(input_folder + "/" + sample + "/annotation/sccmec/" + sample + ".tsv",
                             sep="\t")
    sccmec_out = sccmec_out.set_index("sample")

    return sccmec_out


# Run main script
if __name__ == "__main__":
    program_description = "Script to process the output of the MGAP pipeline, \
        and consolidate into different tables for visualization"

    parser = argparse.ArgumentParser(description=program_description)

    # Arguments
    parser.add_argument("-i", "--input_folder",
                        help="Path to the folder containing the MGAP output",
                        required=True, type=str)
    parser.add_argument("-o", "--output_folder", help="Output folder for the tables",
                        required=True, type=str)
    parser.add_argument("-r", "--replace", help="Replace existing samples",
                        required=True, type=str)

    args = parser.parse_args()

    # Create output folder
    if not os.path.exists(args.output_folder):
        os.makedirs(args.output_folder)

    # Read the input folder
    ## Get samples names
    sample_names = get_sample_names(args.input_folder)

    # Parse the read processing results
    fastp_results = []
    mash_results = []
    bracken_results = []

    for sample in sample_names:
        fastp, mash, bracken = parse_read_processing(args.input_folder, sample)
        fastp_results.append(fastp)
        mash_results.append(mash)
        bracken_results.append(bracken)

    df_fastp = pd.concat(fastp_results)
    df_mash = pd.concat(mash_results)
    df_bracken = pd.concat(bracken_results)

    # Parse the assembly results
    qc_assembly = []
    for sample in sample_names:
        qc = parse_assembly_qc(args.input_folder, sample)
        qc_assembly.append(qc)

    df_qc = pd.concat(qc_assembly)

    # Parse the annotation results
    checkm2_results = []
    mlst_results = []
    bakta_results = []
    amrfinder_results = []
    genomad_virus_results = []
    genomad_plasmid_results = []
    kleborate_results = []
    sccmec_results = []

    for sample in sample_names:
        checkm2, mlst, bakta, amrfinder, genomad_virus, genomad_plasmid = parse_annotation(args.input_folder, sample)
        checkm2_results.append(checkm2)
        mlst_results.append(mlst)
        bakta_results.append(bakta)
        amrfinder_results.append(amrfinder)
        genomad_virus_results.append(genomad_virus)
        genomad_plasmid_results.append(genomad_plasmid)

        # Specific annotations
        if os.path.exists(args.input_folder + "/" + sample + "/annotation/kleborate"):
            kleborate = parse_kleborate(args.input_folder, sample)
            kleborate_results.append(kleborate)

        if os.path.exists(args.input_folder + "/" + sample + "/annotation/sccmec"):
            sccmec = parse_sccmec(args.input_folder, sample)

    df_checkm2 = pd.concat(checkm2_results)
    df_mlst = pd.concat(mlst_results)
    df_bakta = pd.concat(bakta_results)
    df_amrfinder = pd.concat(amrfinder_results)
    df_genome_virus = pd.concat(genomad_virus_results)
    df_genome_plasmid = pd.concat(genomad_plasmid_results)

    try:
        df_kleborate = pd.concat(kleborate_results)
        df_sccmec = pd.concat(sccmec_results)
    except ValueError:
        df_kleborate = None
        df_sccmec = None


    # Write the results
    if args.replace == "Yes":
        df_fastp.to_csv(args.output_folder + "/fastp_results.tsv", sep="\t", index_label = "sample")
        df_mash.to_csv(args.output_folder + "/mash_results.tsv", sep="\t", index_label = "sample")
        df_bracken.to_csv(args.output_folder + "/bracken_results.tsv", sep="\t", index_label = "sample")
        df_qc.to_csv(args.output_folder + "/qc_assembly.tsv", sep="\t", index_label = "sample")
        df_checkm2.to_csv(args.output_folder + "/checkm2_results.tsv", sep="\t", index_label = "sample")
        df_mlst.to_csv(args.output_folder + "/mlst_results.tsv", sep="\t", index_label = "sample")
        df_bakta.to_csv(args.output_folder + "/bakta_results.tsv", sep="\t", index_label = "sample")
        df_amrfinder.to_csv(args.output_folder + "/amrfinder_results.tsv", sep="\t", index_label = "sample")
        df_genome_virus.to_csv(args.output_folder + "/genomad_virus_results.tsv", sep="\t", index_label = "sample")
        df_genome_plasmid.to_csv(args.output_folder + "/genomad_plasmid_results.tsv", sep="\t", index_label = "sample")

        if df_kleborate is not None:
            df_kleborate.to_csv(args.output_folder + "/kleborate_results.tsv", sep="\t", index_label = "sample")
        if df_sccmec is not None:
            df_sccmec.to_csv(args.output_folder + "/sccmec_results.tsv", sep="\t", index_label = "sample")

    elif args.replace == "No":
        df_fastp.to_csv(args.output_folder + "/fastp_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_mash.to_csv(args.output_folder + "/mash_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_bracken.to_csv(args.output_folder + "/bracken_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_qc.to_csv(args.output_folder + "/qc_assembly.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_checkm2.to_csv(args.output_folder + "/checkm2_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_mlst.to_csv(args.output_folder + "/mlst_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_bakta.to_csv(args.output_folder + "/bakta_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_amrfinder.to_csv(args.output_folder + "/amrfinder_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_genome_virus.to_csv(args.output_folder + "/genomad_virus_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        df_genome_plasmid.to_csv(args.output_folder + "/genomad_plasmid_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")

        if df_kleborate is not None:
            df_kleborate.to_csv(args.output_folder + "/kleborate_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")
        if df_sccmec is not None:
            df_sccmec.to_csv(args.output_folder + "/sccmec_results.tsv", sep="\t", index_label = "sample", header=False, mode="a")

    else:
        print("Error: replace argument must be Yes or No")